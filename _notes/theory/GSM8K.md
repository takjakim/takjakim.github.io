---
title: GSM8K
last_modified_at: '2026-02-15'
permalink: /theory/gsm8k/
---

# GSM8K

## 한 줄 요약
초등학교 수준의 수학 문장제 8,000개로 AI의 수학 추론 능력을 평가하는 벤치마크.

## 쉬운 설명
GSM8K는 "Grade School Math 8K"의 약자로, **초등학교 수학 문제 8,000개**를 모은 데이터셋이다.

### 왜 초등학교 수학인가요?
초등학교 문제라고 쉽다고 생각할 수 있지만, AI에게는 매우 어렵다. 왜냐하면:
- **다단계 추론** 필요: 한 번에 답이 안 나옴
- **상식 활용**: 문맥 이해 필요
- **논리적 사고**: 단계별로 생각해야 함

### 예시 문제:
```
문제:
철수는 사탕을 12개 가지고 있었습니다.
영희에게 3개를 주고, 민수에게 4개를 주었습니다.
그 후 어머니가 7개를 더 주셨습니다.
철수는 지금 사탕을 몇 개 가지고 있나요?

풀이 과정 (Chain-of-Thought):
1. 처음 사탕: 12개
2. 영희에게 준 후: 12 - 3 = 9개
3. 민수에게 준 후: 9 - 4 = 5개
4. 어머니가 주신 후: 5 + 7 = 12개

답: 12개
```

AI는 이런 **단계별 추론**을 모두 해야 한다.

### 난이도 범위:
- 쉬운 문제: 1~2 단계 (예: 덧셈, 뺄셈)
- 중간 문제: 3~4 단계 (예: 비율, 분수)
- 어려운 문제: 5~7 단계 (예: 복합 문제)

## 핵심 포인트
- **8,000개 문제**: 7,500개 학습용 + 500개 테스트용
- **다단계 추론**: 평균 3~5 단계 계산 필요
- **자연어 이해**: 수학 공식이 아닌 문장으로 된 문제
- **단계별 풀이 필수**: Chain-of-Thought 방식으로 평가

## 관련 개념
- [[Chain-of-Thought (CoT)]] - GSM8K 문제 풀이에 필수적인 방법
- [[MMLU]] - 종합 지식 평가 (GSM8K는 수학 특화)
- [[HumanEval]] - 코드 생성 평가 (GSM8K는 수학 추론)
- [[Curriculum Learning]] - 쉬운 수학 문제→어려운 문제 순서로 학습
- [[Perplexity (PPL)]] - 문제 난이도 측정

## R4 연구에서의 역할
GSM8K는 R4 연구에서 **수학 추론 능력** 평가에 사용된다.

### 왜 GSM8K가 중요한가?
R4 연구의 가설 H3b: **"추론 중심 태스크에서 ZPD-Adaptive 효과가 더 큼"**

GSM8K는 대표적인 **추론 태스크**이므로:
- 난이도 구조가 명확 (단계 수로 측정 가능)
- ZPD Window 효과가 크게 나타날 것으로 예상

### 난이도 측정 (D2: 추론 단계 수):
R4 연구는 GSM8K 문제를 다음과 같이 분류:
```
쉬움:   1~2 단계 (예: "12 + 5는?")
중간:   3~4 단계 (예: "평균 구하기")
어려움: 5~7 단계 (예: "비율과 분수 복합")
```

### ZPD Window 적용 예시:
```
현재 모델 수준: 3단계 문제까지 잘 풀음
ZPD 범위: 3~4단계 문제 선택
→ 5단계 이상은 너무 어려워서 제외
→ 1~2단계는 너무 쉬워서 제외
```

### R4 연구의 GSM8K 사용:
- **학습 데이터**: GSM8K-Train (7,500개)
- **평가 데이터**: GSM8K-Test (500개)
- **평가 방식**: 8-shot (예시 8개 제공)
- **기대 결과**:
  - Random 대비 +5~8% 향상
  - 다른 벤치마크보다 큰 효과 예상 (추론 태스크 특성)

### 태스크 유형별 효과 비교:
| 벤치마크 | 태스크 유형 | ZPD 효과 |
|---------|------------|---------|
| GSM8K | 수학 추론 | **매우 큼** |
| MMLU | 지식 + 추론 | 큼 |
| HumanEval | 코드 생성 | 중간 |

## 더 알아보기
- Cobbe, K., et al. (2021). Training Verifiers to Solve Math Word Problems. *arXiv preprint*.
- 공개 데이터셋: https://github.com/openai/grade-school-math
- GPT-4 정확도: 92%
- GPT-3.5 정확도: 57%
- PaLM 540B + CoT: 56%
- 인간 초등학생 정확도: 80~90%
- 후속 연구: MATH (대학 수준 수학 문제)
