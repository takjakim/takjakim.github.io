# Perplexity (PPL)

## 한 줄 요약
언어 모델이 문장을 얼마나 "당황스러워하는지" 측정하는 지표로, 낮을수록 모델이 그 문장을 잘 예측한다는 의미.

## 쉬운 설명
Perplexity(당혹도, 혼란도)는 언어 모델의 성능을 평가하는 대표적인 지표입니다. "PPL"이라고 줄여서 부르기도 해요.

쉽게 비유하자면, **퀴즈의 난이도**라고 생각하면 됩니다.

예를 들어볼게요:
- 문장 A: "나는 학교에 ___" → 다음 단어로 "간다"를 예측하기 쉬움 → **낮은 PPL**
- 문장 B: "양자역학의 불확정성 원리는 ___" → 다음 단어 예측하기 어려움 → **높은 PPL**

모델이 다음 단어를 잘 예측할수록 PPL이 낮고, 못할수록 높습니다.

### 수학적으로는 이렇게 계산해요:
```
PPL = exp(평균 Loss)
```

- Loss가 낮으면 (잘 예측) → PPL도 낮음 → 모델이 우수함
- Loss가 높으면 (못 예측) → PPL도 높음 → 모델이 부족함

예를 들어:
- GPT 모델이 뉴스 기사를 읽을 때: PPL = 20 (낮음, 쉬움)
- GPT 모델이 전문 의학 논문을 읽을 때: PPL = 80 (높음, 어려움)

## 핵심 포인트
- **낮을수록 좋음**: PPL이 낮다 = 모델이 텍스트를 잘 이해한다
- **난이도 측정**: 같은 모델에서 PPL이 높은 데이터 = 어려운 데이터
- **지수 관계**: Loss와 지수(exp) 관계이므로 작은 Loss 차이도 PPL에서는 크게 나타남
- **도메인 의존적**: 같은 모델이라도 뉴스(낮은 PPL) vs 법률 문서(높은 PPL)처럼 차이 남

## 관련 개념
- [[Cross-entropy Loss]] - PPL 계산의 기반이 되는 손실 함수
- [[Curriculum Learning]] - PPL로 난이도를 측정하여 학습 순서 결정
- [[ZPD (근접발달영역)]] - 적정 PPL 범위가 ZPD에 해당
- [[Fine-tuning]] - PPL로 Fine-tuning 진행 상황 모니터링
- [[Confidence (신뢰도)]] - PPL과 함께 모델 성능 측정

## R4 연구에서의 역할
R4 연구에서 PPL은 **ZPD Window를 정하는 핵심 지표**입니다.

구체적인 사용 방법:
1. **현재 모델 능력 측정**: Held-out set에서 평균 PPL 계산
   ```
   예: 현재 PPL = 30
   ```

2. **ZPD 범위 설정**:
   ```
   ZPD 하한 = PPL × 1.1 = 30 × 1.1 = 33
   ZPD 상한 = PPL × 1.3 = 30 × 1.3 = 39
   ```

3. **데이터 선별**: PPL이 33~39 사이인 데이터만 선택해서 학습

4. **500 스텝마다 갱신**: 모델이 발전하면 PPL이 낮아지므로, ZPD 범위도 재계산

### 왜 PPL을 사용하나?
- **직관적**: 숫자가 클수록 어렵다는 의미가 명확
- **표준화**: 언어 모델 연구에서 널리 사용되는 지표
- **계산 효율**: Loss에서 바로 계산 가능 (추가 계산 비용 없음)
- **다차원 난이도**: PPL + [[Confidence (신뢰도)]] + [[Entropy (엔트로피)]]를 함께 사용하여 더 정확한 측정

## 더 알아보기
- PPL의 수학적 정의: exp(−(1/N) Σ log P(w_i | context))
- 정보 이론에서 유래: "평균적으로 몇 개의 선택지 중 고민하는가"
- 낮은 PPL 예시: GPT-4가 영어 위키피디아 읽을 때 ~10-20
- 높은 PPL 예시: GPT-4가 고대 라틴어 읽을 때 ~100+
- BERT, GPT 같은 모델들은 Pre-training 시 PPL 기준으로 성능 평가
